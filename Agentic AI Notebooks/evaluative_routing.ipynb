{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluative Routing\n",
    "\n",
    "One of the most interesting applications of JSON outputs in agentic development is *routing* the workflow to different actions depending on the LLM's assessment.\n",
    "\n",
    "Prompt a model with a collection of context and criteria and then ask it to create a decision. That decision can then be parsed as JSON and used to shape complex, versatile systems.\n",
    "\n",
    "As routing becomes increasingly elaborate, we begin to see the border between *workflows* and *agents* grow clearer. Remember, we've defined 'autonomous agents' as AI systems that decide their own path (and the number of steps it will take) to accomplish a given task. A particularly sophisticated type of routing that leads to autonomous behavior is something we might call *evaluative routing*—where the model evaluates the output it produces and decides if it needs more work or if it's ready to be handed back to the user.\n",
    "\n",
    "By making decisions based on qualitative evaluations, our agentic system can begin behaving like a totally unsupervised agent. Let's see it in practice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, let's import the necessary libraries and set up our connection to the OpenAI API:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "▶ Jupyter Help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import json\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "def get_completion(prompt, system_prompt=\"You are a helpful assistant.\", json_mode=False):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[{\"role\": \"system\", \"content\": system_prompt}, {\"role\": \"user\", \"content\": prompt}],\n",
    "        response_format={\"type\": \"json_object\"} if json_mode else None\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, take a look at the following cell. In it, we use JSON mode to instruct the model to route a customer service request to either a human or a chatbot depending on a set of criteria. Try changing the customer support request in the `request` variable to a few different types of queries to see how the model behaves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def route_customer(request):\n",
    "    system_prompt = \"You're a helpful assistant that outputs JSON. Do not include any markdown backticks in your response.\"\n",
    "    prompt = f\"\"\"\n",
    "    <instructions>Below you'll see a customer service request.\n",
    "    Your job is to decide whether the request should be routed to a human or a chatbot.\n",
    "    You should also provide a reason for your decision.\n",
    "    The request is:\n",
    "    {{request}}\n",
    "    </instructions>\n",
    "    <format>\n",
    "    Your response should have two fields:\n",
    "    - \"decision\": \"human\" or \"chatbot\"\n",
    "    - \"reason\": a short explanation for your decision\n",
    "\n",
    "    Route to a human if:\n",
    "    - The request involves a complaint or dissatisfaction\n",
    "    - The request requires account changes or financial transactions\n",
    "    - The request mentions legal issues or threatens escalation\n",
    "\n",
    "    Route to a chatbot if:\n",
    "    - The request is for basic information or FAQs\n",
    "    - The request is for simple status updates\n",
    "    - The request is for general product information\n",
    "\n",
    "    For instance:\n",
    "    {{\n",
    "        \"decision\": \"human\",\n",
    "        \"reason\": \"The request is a complex issue that requires a human touch.\"\n",
    "    }}\n",
    "    </format>\n",
    "    \"\"\"\n",
    "    response = get_completion(prompt, system_prompt, json_mode=True)\n",
    "    return response\n",
    "\n",
    "request = \"I need help with my account.\"\n",
    "decision = route_customer(request)\n",
    "json_decision = json.loads(decision)\n",
    "decision = json_decision['decision']\n",
    "reason = json_decision['reason']\n",
    "\n",
    "print(\"Request:\", request)\n",
    "print(\"Decision: \", decision)\n",
    "print(\"Reason: \", reason)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checkpoint 1/3\n",
    "\n",
    "Now, assuming you've got the `decision` and `reason` variables accessible from the last cell, let's write a little code that routes the LLM's decision to two different outcomes. We've defined two placeholder functions `handle_by_chatbot` and `handle_by_human`, which should be called depending on the content of the `decision` variable.\n",
    "\n",
    "In the second half of the cell, write a control flow that calls `handle_by_chatbot` if `decision` is equal to `\"chatbot\"` and `handle_by_human` if `decision` is equal to `\"human\"`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
